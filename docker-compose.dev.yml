services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: always

  kafka:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD", "cub", "kafka-ready", "-b", "kafka:9092", "1", "1"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - zookeeper
    restart: always

  init-kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
    env_file: .env
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list
      
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $$KAFKA_AUDIO_REQUESTS_TOPIC --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $$KAFKA_STT_RESULTS_TOPIC --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $$KAFKA_NOTIFICATION_TOPIC --replication-factor 1 --partitions 1
      
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      "

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    env_file: .env
    command: server /data --console-address ":9001"
    volumes:
      - "./data/minio_data:/data"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always

  # Nginx (리버스 프록시)
  nginx:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.dev.conf:/etc/nginx/nginx.conf
    depends_on:
      - api_gateway
    restart: always

  api_gateway:
    build: ./api_gateway
    ports: ["8000:8000"]
    env_file: .env
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_started
      postgres:
        condition: service_started
    volumes: ["./api_gateway:/app"]
    restart: always

  stt_worker_base:
    build:
      context: ./stt_worker/stt_worker_base
      dockerfile: Dockerfile
    env_file: .env
    environment:
      - KAFKA_TARGET_TOPIC=stt_requests_base
      - MODEL_NAME=base
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy
      api_gateway:
        condition: service_started
    restart: always

  # stt_worker_medium:
  #   build:
  #     context: .
  #     dockerfile: ./stt_worker/stt_worker_medium/Dockerfile
  #   volumes: ["./stt_worker/stt_worker_medium:/app"]
  #   environment:
  #     - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
  #     - KAFKA_TARGET_TOPIC=stt_requests_medium # ✨ medium 워커는 이 토픽을 구독
  #     - MODEL_NAME=medium # ✨ medium 모델을 로드
  #     - MINIO_URL=minio:9000
  #     - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
  #     - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
  #   depends_on: [kafka, minio]

  # stt_worker_large:
  #   build:
  #     context: .
  #     dockerfile: ./stt_worker/stt_worker_large/Dockerfile
  #   volumes: ["./stt_worker/stt_worker_large:/app"]
  #   environment:
  #     - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
  #     - KAFKA_TARGET_TOPIC=stt_requests_large # ✨ large 워커는 이 토픽을 구독
  #     - MODEL_NAME=large-v3 # ✨ large 모델을 로드  
  #     - MINIO_URL=minio:9000
  #     - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
  #     - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
  #   depends_on: [kafka, minio]

  # stt_worker_whisperx:
  #   build:
  #     context: .
  #     dockerfile: ./stt_worker/stt_worker_whisperx/Dockerfile
  #    deploy: # GPU 할당
  #      resources:
  #        reservations:
  #          devices: [{driver: nvidia, count: 1, capabilities: [gpu]}]
  #   volumes: ["./stt_worker/stt_worker_whisperx:/app"]
  #   environment:
  #     - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
  #     - KAFKA_TARGET_TOPIC=stt_requests_whisperx
  #     - MODEL_NAME=large-v3
  #     - MINIO_URL=minio:9000
  #     - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
  #     - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
  #     - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
  #   depends_on: [kafka, minio]
  
  result_handler:
    build: ./result_handler
    env_file: .env
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
      api_gateway:
        condition: service_started
    restart: always


  postgres:
    image: postgres:15
    env_file: .env
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always


  admin_ui:
    build:
      context: ./admin_ui
      dockerfile: Dockerfile
    ports:
      - "80:80"
    environment:
      - REACT_APP_API_URL=http://localhost:8000 # Nginx를 통해 외부로 노출되므로 localhost
    depends_on: [api_gateway]

  # --- 모니터링 스택 ---
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
    command: --config.file=/etc/prometheus/prometheus.yml
    restart: always

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana
    restart: always

  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.6.0
    ports: ["9308:9308"]
    command: --kafka.server=kafka:29092
    depends_on: [kafka]
    
  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.12.0
    ports: ["9187:9187"]
    environment:
      - DATA_SOURCE_NAME=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    depends_on: [postgres]

volumes:
  minio_data:
  postgres_data:
  prometheus_data:
  grafana_data:
